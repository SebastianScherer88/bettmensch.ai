{"metadata": {"name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "generate_name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-", "namespace": "argo", "uid": "d48f4d8d-61b1-4b86-a200-49c525c6f516", "resource_version": "17861", "generation": 12, "creation_timestamp": "test-datetime-value", "labels": {"workflows.argoproj.io/completed": "true", "workflows.argoproj.io/creator": "system-serviceaccount-argo-argo-server", "workflows.argoproj.io/phase": "Succeeded"}, "annotations": {"karpenter.sh/do-not-disrupt": "true", "workflows.argoproj.io/pod-name-format": "v2"}, "managed_fields": [{"manager": "argo", "operation": "Update", "api_version": "argoproj.io/v1alpha1", "time": "test-datetime-value", "fields_type": "FieldsV1", "fields_v1": {"f:metadata": {"f:generateName": {}, "f:labels": {".": {}, "f:workflows.argoproj.io/creator": {}}}, "f:spec": {}}}, {"manager": "workflow-controller", "operation": "Update", "api_version": "argoproj.io/v1alpha1", "time": "test-datetime-value", "fields_type": "FieldsV1", "fields_v1": {"f:metadata": {"f:annotations": {".": {}, "f:karpenter.sh/do-not-disrupt": {}, "f:workflows.argoproj.io/pod-name-format": {}}, "f:labels": {"f:workflows.argoproj.io/completed": {}, "f:workflows.argoproj.io/phase": {}}}, "f:status": {}}}]}, "spec": {"arguments": {"parameters": [{"name": "max_time", "value": "00:00:00:20"}]}, "workflow_template_ref": {"name": "pipeline-test-lightning-gpu-pipeline-9r6h2"}}, "status": {"phase": "Succeeded", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "7/7", "nodes": {"pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "type": "DAG", "display_name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "template_name": "bettmensch-ai-dag", "template_scope": "local/", "phase": "Succeeded", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "7/7", "resources_duration": {"cpu": 128, "memory": 2228, "nvidia.com/gpu": 179}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-966953919"], "outbound_nodes": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1639120660", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3295920951", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3164367506", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2871044736", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1820439476"]}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1639120660": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1639120660", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0-worker-1(0)", "type": "Pod", "display_name": "lightning-ddp-0-worker-1(0)", "template_name": "lightning-ddp-1", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 34, "memory": 587, "nvidia.com/gpu": 48}, "node_flag": {"retried": true}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:23.332028", "value_from": {"path": "duration"}}], "exit_code": "0"}, "host_node_name": "ip-10-0-49-51.us-east-2.compute.internal"}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1697154233": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1697154233", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0(0)", "type": "Pod", "display_name": "lightning-ddp-0(0)", "template_name": "lightning-ddp-0", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 26, "memory": 467, "nvidia.com/gpu": 37}, "node_flag": {"retried": true}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:23.295598", "value_from": {"path": "duration"}}], "exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2871044736", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3009250645"], "host_node_name": "ip-10-0-49-145.us-east-2.compute.internal"}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1820439476": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1820439476", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.show-duration-param-0(0)", "type": "Pod", "display_name": "show-duration-param-0(0)", "template_name": "show-duration-param", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 1, "memory": 24}, "node_flag": {"retried": true}, "inputs": {"parameters": [{"name": "a", "value": "0:00:23.295598"}]}, "outputs": {"exit_code": "0"}, "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal"}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2032602050": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2032602050", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0", "type": "Retry", "display_name": "lightning-ddp-0", "template_name": "lightning-ddp-0", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "3/3", "resources_duration": {"cpu": 27, "memory": 491, "nvidia.com/gpu": 37}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:23.295598", "value_from": {"path": "duration"}}], "exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1697154233"]}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2871044736": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2871044736", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-delete-torch-service", "type": "Pod", "display_name": "lightning-ddp-delete-torch-service", "template_name": "lightning-ddp-delete-torch-service", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 0, "memory": 0}, "outputs": {"exit_code": "0"}, "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal"}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3009250645": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3009250645", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.show-duration-param-0", "type": "Retry", "display_name": "show-duration-param-0", "template_name": "show-duration-param", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 1, "memory": 24}, "inputs": {"parameters": [{"name": "a", "value": "0:00:23.295598"}]}, "outputs": {"exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1820439476"]}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3164367506": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3164367506", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0-worker-3(0)", "type": "Pod", "display_name": "lightning-ddp-0-worker-3(0)", "template_name": "lightning-ddp-3", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 36, "memory": 606, "nvidia.com/gpu": 50}, "node_flag": {"retried": true}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:22.990339", "value_from": {"path": "duration"}}], "exit_code": "0"}, "host_node_name": "ip-10-0-50-29.us-east-2.compute.internal"}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3295920951": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3295920951", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0-worker-2(0)", "type": "Pod", "display_name": "lightning-ddp-0-worker-2(0)", "template_name": "lightning-ddp-2", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 31, "memory": 544, "nvidia.com/gpu": 44}, "node_flag": {"retried": true}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:22.838134", "value_from": {"path": "duration"}}], "exit_code": "0"}, "host_node_name": "ip-10-0-50-166.us-east-2.compute.internal"}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-855475196": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-855475196", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0-worker-2", "type": "Retry", "display_name": "lightning-ddp-0-worker-2", "template_name": "lightning-ddp-2", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 31, "memory": 544, "nvidia.com/gpu": 44}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:22.838134", "value_from": {"path": "duration"}}], "exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3295920951"]}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-872252815": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-872252815", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0-worker-3", "type": "Retry", "display_name": "lightning-ddp-0-worker-3", "template_name": "lightning-ddp-3", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 36, "memory": 606, "nvidia.com/gpu": 50}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:22.990339", "value_from": {"path": "duration"}}], "exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3164367506"]}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-905808053": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-905808053", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-0-worker-1", "type": "Retry", "display_name": "lightning-ddp-0-worker-1", "template_name": "lightning-ddp-1", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 34, "memory": 587, "nvidia.com/gpu": 48}, "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30", "value": "00:00:00:20"}, {"name": "duration", "default": "null", "value": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value": "0:00:23.332028", "value_from": {"path": "duration"}}], "exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1639120660"]}, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-966953919": {"id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-966953919", "name": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d.lightning-ddp-create-torch-service", "type": "Pod", "display_name": "lightning-ddp-create-torch-service", "template_name": "lightning-ddp-create-torch-service", "template_scope": "local/", "phase": "Succeeded", "boundary_id": "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d", "started_at": "test-datetime-value", "finished_at": "test-datetime-value", "progress": "1/1", "resources_duration": {"cpu": 0, "memory": 0}, "outputs": {"exit_code": "0"}, "children": ["pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-905808053", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-855475196", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-872252815", "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2032602050"], "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal"}}, "stored_templates": {"namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/bettmensch-ai-dag": {"name": "bettmensch-ai-dag", "inputs": {}, "outputs": {}, "metadata": {}, "dag": {"tasks": [{"name": "lightning-ddp-create-torch-service", "template": "lightning-ddp-create-torch-service", "arguments": {}}, {"name": "lightning-ddp-0", "template": "lightning-ddp-0", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-0-worker-1", "template": "lightning-ddp-1", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-0-worker-2", "template": "lightning-ddp-2", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-0-worker-3", "template": "lightning-ddp-3", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-delete-torch-service", "template": "lightning-ddp-delete-torch-service", "arguments": {}, "depends": "lightning-ddp-0"}, {"name": "show-duration-param-0", "template": "show-duration-param", "arguments": {"parameters": [{"name": "a", "value": "{{tasks.lightning-ddp-0.outputs.parameters.duration}}"}]}, "depends": "lightning-ddp-0"}]}}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/lightning-ddp-0": {"name": "lightning-ddp-0", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "0"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "ports": [{"container_port": 29200, "name": "ddp", "protocol": "TCP"}], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "0"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/lightning-ddp-1": {"name": "lightning-ddp-1", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "1"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/lightning-ddp-2": {"name": "lightning-ddp-2", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "2"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "2"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/lightning-ddp-3": {"name": "lightning-ddp-3", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "3"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "3"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/lightning-ddp-create-torch-service": {"name": "lightning-ddp-create-torch-service", "inputs": {}, "outputs": {}, "metadata": {}, "resource": {"action": "create", "manifest": "apiVersion: v1\nkind: Service\nmetadata:\n  name: lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8\n  namespace: argo\n  labels:\n    app: lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8\nspec:\n  clusterIP: None  # ClusterIP set to None for headless service.\n  ports:\n  - name: ddp  # Port for torchrun master<->worker node coms.\n    port: 29200\n    targetPort: 29200\n  selector:\n    torch-job: lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8\n    torch-node: '0'  # Selector for pods associated with this service.\n"}}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/lightning-ddp-delete-torch-service": {"name": "lightning-ddp-delete-torch-service", "inputs": {}, "outputs": {}, "metadata": {}, "resource": {"action": "delete", "flags": ["service", "--selector", "torch-job=lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "-n", "argo"]}}, "namespaced/pipeline-test-lightning-gpu-pipeline-9r6h2/show-duration-param": {"name": "show-duration-param", "inputs": {"parameters": [{"name": "a"}]}, "outputs": {}, "metadata": {}, "script": {"image": "bettmensch88/bettmensch.ai:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: a = json.loads(r'''{{inputs.parameters.a}}''')\nexcept: a = r'''{{inputs.parameters.a}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\ndef show_parameter(a: InputParameter) -> None:\n    \"\"\"When decorated with the bettmensch_ai.components.component decorator,\n    implements a bettmensch_ai.Component that prints the values of its\n    InputParameter.\"\"\"\n    print(f'Content of input parameter a is: {a}')\nshow_parameter(a)", "name": "", "command": ["python"], "resources": {"limits": {"cpu": "100m", "memory": "100Mi"}, "requests": {"cpu": "100m", "memory": "100Mi"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}}}, "conditions": [{"type": "PodRunning", "status": "False"}, {"type": "Completed", "status": "True"}], "resources_duration": {"cpu": 128, "memory": 2228, "nvidia.com/gpu": 179}, "stored_workflow_template_spec": {"templates": [{"name": "lightning-ddp-create-torch-service", "inputs": {}, "outputs": {}, "metadata": {}, "resource": {"action": "create", "manifest": "apiVersion: v1\nkind: Service\nmetadata:\n  name: lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8\n  namespace: argo\n  labels:\n    app: lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8\nspec:\n  clusterIP: None  # ClusterIP set to None for headless service.\n  ports:\n  - name: ddp  # Port for torchrun master<->worker node coms.\n    port: 29200\n    targetPort: 29200\n  selector:\n    torch-job: lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8\n    torch-node: '0'  # Selector for pods associated with this service.\n"}}, {"name": "lightning-ddp-delete-torch-service", "inputs": {}, "outputs": {}, "metadata": {}, "resource": {"action": "delete", "flags": ["service", "--selector", "torch-job=lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "-n", "argo"]}}, {"name": "bettmensch-ai-dag", "inputs": {}, "outputs": {}, "metadata": {}, "dag": {"tasks": [{"name": "lightning-ddp-create-torch-service", "template": "lightning-ddp-create-torch-service", "arguments": {}}, {"name": "lightning-ddp-0", "template": "lightning-ddp-0", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-0-worker-1", "template": "lightning-ddp-1", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-0-worker-2", "template": "lightning-ddp-2", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-0-worker-3", "template": "lightning-ddp-3", "arguments": {"parameters": [{"name": "max_time", "value": "{{workflow.parameters.max_time}}"}]}, "depends": "lightning-ddp-create-torch-service"}, {"name": "lightning-ddp-delete-torch-service", "template": "lightning-ddp-delete-torch-service", "arguments": {}, "depends": "lightning-ddp-0"}, {"name": "show-duration-param-0", "template": "show-duration-param", "arguments": {"parameters": [{"name": "a", "value": "{{tasks.lightning-ddp-0.outputs.parameters.duration}}"}]}, "depends": "lightning-ddp-0"}]}}, {"name": "lightning-ddp-0", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "0"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "ports": [{"container_port": 29200, "name": "ddp", "protocol": "TCP"}], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "0"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, {"name": "lightning-ddp-1", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "1"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, {"name": "lightning-ddp-2", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "2"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "2"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, {"name": "lightning-ddp-3", "inputs": {"parameters": [{"name": "max_time", "default": "00:00:00:30"}, {"name": "duration", "default": "null"}]}, "outputs": {"parameters": [{"name": "duration", "value_from": {"path": "duration"}}]}, "metadata": {"labels": {"torch-job": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8", "torch-node": "3"}}, "script": {"image": "bettmensch88/bettmensch.ai-lightning:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: max_time = json.loads(r'''{{inputs.parameters.max_time}}''')\nexcept: max_time = r'''{{inputs.parameters.max_time}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef lightning_ddp(max_time: InputParameter='00:00:00:30', duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    from datetime import datetime as dt\n    import lightning.pytorch as pl\n    import torch\n    from bettmensch_ai.components.torch_utils import LaunchConfigSettings\n    from lightning.pytorch.strategies import DDPStrategy\n    start = dt.now()\n\n    class ToyExample(pl.LightningModule):\n\n        def __init__(self, model):\n            super().__init__()\n            self.model = model\n\n        def training_step(self, batch):\n            loss = self.model(batch).sum()\n            return loss\n\n        def configure_optimizers(self):\n            return torch.optim.Adam(self.model.parameters())\n    model = torch.nn.Linear(32, 2)\n    pl_module = ToyExample(model)\n    train_dataloader = torch.utils.data.DataLoader(torch.randn(8, 32))\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    process_group_backend = 'nccl' if has_gpu else 'gloo'\n    accelerator = 'gpu' if has_gpu else 'cpu'\n    ddp = DDPStrategy(process_group_backend=process_group_backend)\n    launch_settings = LaunchConfigSettings()\n    trainer = pl.Trainer(strategy=ddp, accelerator=accelerator, num_nodes=launch_settings.max_nodes, devices=launch_settings.nproc_per_node, max_time=max_time)\n    trainer.fit(pl_module, train_dataloader)\n    if duration is not None:\n        duration.assign(dt.now() - start)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(lightning_ddp)\n\ntorch_distributed_function(max_time,duration)", "name": "", "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO"}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "4"}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "3"}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork"}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "lightning-ddp-0-3278f52c-b445-42e4-8e6e-ad2e351afcc8.argo.svc.cluster.local"}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200"}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1"}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0"}], "resources": {"limits": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}, "requests": {"cpu": "700m", "memory": "1Gi", "nvidia.com/gpu": "1"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}, "tolerations": [{"key": "nvidia.com/gpu", "operator": "Exists", "effect": "NoSchedule"}], "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}"}, {"name": "show-duration-param", "inputs": {"parameters": [{"name": "a"}]}, "outputs": {}, "metadata": {}, "script": {"image": "bettmensch88/bettmensch.ai:3.11-latest", "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: a = json.loads(r'''{{inputs.parameters.a}}''')\nexcept: a = r'''{{inputs.parameters.a}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\ndef show_parameter(a: InputParameter) -> None:\n    \"\"\"When decorated with the bettmensch_ai.components.component decorator,\n    implements a bettmensch_ai.Component that prints the values of its\n    InputParameter.\"\"\"\n    print(f'Content of input parameter a is: {a}')\nshow_parameter(a)", "name": "", "command": ["python"], "resources": {"limits": {"cpu": "100m", "memory": "100Mi"}, "requests": {"cpu": "100m", "memory": "100Mi"}}, "image_pull_policy": "Always"}, "retry_strategy": {"limit": "1", "retry_policy": "OnError"}}], "entrypoint": "bettmensch-ai-dag", "arguments": {"parameters": [{"name": "max_time", "value": "00:00:00:20"}]}, "service_account_name": "argo-workflow", "workflow_template_ref": {"name": "pipeline-test-lightning-gpu-pipeline-9r6h2"}}, "artifact_repository_ref": {"config_map": "artifact-repositories", "key": "bettmensch-ai-artifact-repository", "namespace": "argo", "artifact_repository": {"s3": {"endpoint": "s3.us-east-2.amazonaws.com", "bucket": "bettmensch-ai-artifact-repository", "insecure": true}}}, "artifact_gc_status": {"not_specified": true}, "task_results_completion_status": {"pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1639120660": true, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1697154233": true, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-1820439476": true, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-2871044736": true, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3164367506": true, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-3295920951": true, "pipeline-test-lightning-gpu-pipeline-9r6h2-flow-c7v5d-966953919": true}}}