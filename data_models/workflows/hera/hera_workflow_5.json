{"api_version": null, "kind": null, "metadata": {"annotations": {"karpenter.sh/do-not-disrupt": "true", "workflows.argoproj.io/pod-name-format": "v2"}, "cluster_name": null, "creation_timestamp": "test-datetime-value", "deletion_grace_period_seconds": null, "deletion_timestamp": null, "finalizers": null, "generate_name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-", "generation": 11, "labels": {"workflows.argoproj.io/completed": "true", "workflows.argoproj.io/creator": "system-serviceaccount-argo-argo-server", "workflows.argoproj.io/phase": "Succeeded"}, "managed_fields": [{"api_version": "argoproj.io/v1alpha1", "fields_type": "FieldsV1", "fields_v1": {}, "manager": "argo", "operation": "Update", "subresource": null, "time": "test-datetime-value"}, {"api_version": "argoproj.io/v1alpha1", "fields_type": "FieldsV1", "fields_v1": {}, "manager": "workflow-controller", "operation": "Update", "subresource": null, "time": "test-datetime-value"}], "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "namespace": "argo", "owner_references": null, "resource_version": "11623", "self_link": null, "uid": "c085649e-4392-4616-b1fd-2e553aebd469"}, "spec": {"active_deadline_seconds": null, "affinity": null, "archive_logs": null, "arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}]}, "artifact_gc": null, "artifact_repository_ref": null, "automount_service_account_token": null, "dns_config": null, "dns_policy": null, "entrypoint": null, "executor": null, "hooks": null, "host_aliases": null, "host_network": null, "image_pull_secrets": null, "metrics": null, "node_selector": null, "on_exit": null, "parallelism": null, "pod_disruption_budget": null, "pod_gc": null, "pod_metadata": null, "pod_priority": null, "pod_priority_class_name": null, "pod_spec_patch": null, "priority": null, "retry_strategy": null, "scheduler_name": null, "security_context": null, "service_account_name": null, "shutdown": null, "suspend": null, "synchronization": null, "template_defaults": null, "templates": null, "tolerations": null, "ttl_strategy": null, "volume_claim_gc": null, "volume_claim_templates": null, "volumes": null, "workflow_metadata": null, "workflow_template_ref": {"cluster_scope": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx"}}, "status": {"artifact_gc_status": {"not_specified": true, "pods_recouped": null, "strategies_processed": null}, "artifact_repository_ref": {"artifact_repository": {"archive_logs": null, "artifactory": null, "azure": null, "gcs": null, "hdfs": null, "oss": null, "s3": {"access_key_secret": null, "bucket": "bettmensch-ai-artifact-repository", "ca_secret": null, "create_bucket_if_not_present": null, "encryption_options": null, "endpoint": "s3.us-east-2.amazonaws.com", "insecure": true, "key_format": null, "key_prefix": null, "region": null, "role_arn": null, "secret_key_secret": null, "use_sdk_creds": null}}, "config_map": "artifact-repositories", "default": null, "key": "bettmensch-ai-artifact-repository", "namespace": "argo"}, "compressed_nodes": null, "conditions": [{"message": null, "status": "False", "type": "PodRunning"}, {"message": null, "status": "True", "type": "Completed"}], "estimated_duration": null, "finished_at": "test-datetime-value", "message": null, "nodes": {"pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd": {"boundary_id": null, "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1117923175"], "daemoned": null, "display_name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "inputs": null, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "node_flag": null, "outbound_nodes": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1352423924", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3155590524", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3153917983", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1396147642", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-921081341", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-4186039992", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3570269112"], "outputs": null, "phase": "Succeeded", "pod_ip": null, "progress": "9/9", "resources_duration": {"cpu": 105, "memory": 3878}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "bettmensch-ai-dag", "template_ref": null, "template_scope": "local/", "type": "DAG"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1117923175": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-2818153322", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1366517037", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1316184180", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1332961799", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1282628942", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1299406561"], "daemoned": null, "display_name": "torch-ddp-create-torch-service", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1117923175", "inputs": null, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-create-torch-service", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": null, "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 0, "memory": 0}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-create-torch-service", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1282628942": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-921081341"], "daemoned": null, "display_name": "torch-ddp-0-worker-4", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1282628942", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-4", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 18, "memory": 669}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-4", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1299406561": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-4186039992"], "daemoned": null, "display_name": "torch-ddp-0-worker-5", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1299406561", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-5", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 621}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-5", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1316184180": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3153917983"], "daemoned": null, "display_name": "torch-ddp-0-worker-2", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1316184180", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-2", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 657}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-2", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1332961799": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1396147642"], "daemoned": null, "display_name": "torch-ddp-0-worker-3", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1332961799", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-3", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 621}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-3", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1352423924": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "show-duration-param-0(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1352423924", "inputs": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "a", "value": "60", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.show-duration-param-0(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": null, "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 1, "memory": 24}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "show-duration-param", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1366517037": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3155590524"], "daemoned": null, "display_name": "torch-ddp-0-worker-1", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1366517037", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-1", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 621}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-1", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1396147642": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "torch-ddp-0-worker-3(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-50-203.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1396147642", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-3(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 621}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-3", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-2818153322": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3218331537"], "daemoned": null, "display_name": "torch-ddp-0", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-2818153322", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "3/3", "resources_duration": {"cpu": 19, "memory": 689}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-0", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3153917983": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "torch-ddp-0-worker-2(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3153917983", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-2(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 657}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-2", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3155590524": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "torch-ddp-0-worker-1(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-50-203.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3155590524", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-1(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 621}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-1", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3218331537": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3763294229", "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3570269112"], "daemoned": null, "display_name": "torch-ddp-0(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3218331537", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 18, "memory": 665}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-0", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3570269112": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "torch-ddp-delete-torch-service", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3570269112", "inputs": null, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-delete-torch-service", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": null, "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 0, "memory": 0}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-delete-torch-service", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3763294229": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": ["pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1352423924"], "daemoned": null, "display_name": "show-duration-param-0", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": null, "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3763294229", "inputs": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "a", "value": "60", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.show-duration-param-0", "node_flag": null, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": null, "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 1, "memory": 24}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "show-duration-param", "template_ref": null, "template_scope": "local/", "type": "Retry"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-4186039992": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "torch-ddp-0-worker-5(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-50-203.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-4186039992", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-5(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 17, "memory": 621}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-5", "template_ref": null, "template_scope": "local/", "type": "Pod"}, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-921081341": {"boundary_id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd", "children": null, "daemoned": null, "display_name": "torch-ddp-0-worker-4(0)", "estimated_duration": null, "finished_at": "test-datetime-value", "host_node_name": "ip-10-0-48-52.us-east-2.compute.internal", "id": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-921081341", "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": "null", "value_from": null}]}, "memoization_status": null, "message": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd.torch-ddp-0-worker-4(0)", "node_flag": {"hooked": null, "retried": true}, "outbound_nodes": null, "outputs": {"artifacts": null, "exit_code": "0", "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": "60", "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "phase": "Succeeded", "pod_ip": null, "progress": "1/1", "resources_duration": {"cpu": 18, "memory": 669}, "started_at": "test-datetime-value", "synchronization_status": null, "template_name": "torch-ddp-4", "template_ref": null, "template_scope": "local/", "type": "Pod"}}, "offload_node_status_version": null, "outputs": null, "persistent_volume_claims": null, "phase": "Succeeded", "progress": "9/9", "resources_duration": {"cpu": 105, "memory": 3878}, "started_at": "test-datetime-value", "stored_templates": {"namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/bettmensch-ai-dag": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": {"fail_fast": null, "target": null, "tasks": [{"arguments": {"artifacts": null, "parameters": null}, "continue_on": null, "dependencies": null, "depends": null, "hooks": null, "inline": null, "name": "torch-ddp-create-torch-service", "on_exit": null, "template": "torch-ddp-create-torch-service", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0", "on_exit": null, "template": "torch-ddp-0", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-1", "on_exit": null, "template": "torch-ddp-1", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-2", "on_exit": null, "template": "torch-ddp-2", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-3", "on_exit": null, "template": "torch-ddp-3", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-4", "on_exit": null, "template": "torch-ddp-4", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-5", "on_exit": null, "template": "torch-ddp-5", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": null}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-0", "hooks": null, "inline": null, "name": "torch-ddp-delete-torch-service", "on_exit": null, "template": "torch-ddp-delete-torch-service", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "a", "value": "{{tasks.torch-ddp-0.outputs.parameters.duration}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-0", "hooks": null, "inline": null, "name": "show-duration-param-0", "on_exit": null, "template": "show-duration-param", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}]}, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": null}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "bettmensch-ai-dag", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": null, "scheduler_name": null, "script": null, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/show-duration-param": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "a", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "show-duration-param", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": null, "env_from": null, "image": "bettmensch88/bettmensch.ai:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "100Mi"}, "requests": {"cpu": "100m", "memory": "100Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: a = json.loads(r'''{{inputs.parameters.a}}''')\nexcept: a = r'''{{inputs.parameters.a}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\ndef show_parameter(a: InputParameter) -> None:\n    \"\"\"When decorated with the bettmensch_ai.components.component decorator,\n    implements a bettmensch_ai.Component that prints the values of its\n    InputParameter.\"\"\"\n    print(f'Content of input parameter a is: {a}')\nshow_parameter(a)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-0": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "0"}}, "metrics": null, "name": "torch-ddp-0", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "0", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": [{"container_port": 29200, "host_ip": null, "host_port": null, "name": "ddp", "protocol": "TCP"}], "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-1": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "1"}}, "metrics": null, "name": "torch-ddp-1", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-2": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "2"}}, "metrics": null, "name": "torch-ddp-2", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "2", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-3": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "3"}}, "metrics": null, "name": "torch-ddp-3", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "3", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-4": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "4"}}, "metrics": null, "name": "torch-ddp-4", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "4", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-5": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "5"}}, "metrics": null, "name": "torch-ddp-5", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "5", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-create-torch-service": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": null}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "torch-ddp-create-torch-service", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": {"action": "create", "failure_condition": null, "flags": null, "manifest": "apiVersion: v1\nkind: Service\nmetadata:\n  name: torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2\n  namespace: argo\n  labels:\n    app: torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2\nspec:\n  clusterIP: None  # ClusterIP set to None for headless service.\n  ports:\n  - name: ddp  # Port for torchrun master<->worker node coms.\n    port: 29200\n    targetPort: 29200\n  selector:\n    torch-job: torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2\n    torch-node: '0'  # Selector for pods associated with this service.\n", "manifest_from": null, "merge_strategy": null, "set_owner_reference": null, "success_condition": null}, "retry_strategy": null, "scheduler_name": null, "script": null, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, "namespaced/pipeline-test-torch-cpu-pipeline-2n6rx/torch-ddp-delete-torch-service": {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": null}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "torch-ddp-delete-torch-service", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": {"action": "delete", "failure_condition": null, "flags": ["service", "--selector", "torch-job=torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "-n", "argo"], "manifest": null, "manifest_from": null, "merge_strategy": null, "set_owner_reference": null, "success_condition": null}, "retry_strategy": null, "scheduler_name": null, "script": null, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}}, "stored_workflow_template_spec": {"active_deadline_seconds": null, "affinity": null, "archive_logs": null, "arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "12", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "5", "value_from": null}]}, "artifact_gc": null, "artifact_repository_ref": null, "automount_service_account_token": null, "dns_config": null, "dns_policy": null, "entrypoint": "bettmensch-ai-dag", "executor": null, "hooks": null, "host_aliases": null, "host_network": null, "image_pull_secrets": null, "metrics": null, "node_selector": null, "on_exit": null, "parallelism": null, "pod_disruption_budget": null, "pod_gc": null, "pod_metadata": null, "pod_priority": null, "pod_priority_class_name": null, "pod_spec_patch": null, "priority": null, "retry_strategy": null, "scheduler_name": null, "security_context": null, "service_account_name": "argo-workflow", "shutdown": null, "suspend": null, "synchronization": null, "template_defaults": null, "templates": [{"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": null}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "torch-ddp-create-torch-service", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": {"action": "create", "failure_condition": null, "flags": null, "manifest": "apiVersion: v1\nkind: Service\nmetadata:\n  name: torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2\n  namespace: argo\n  labels:\n    app: torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2\nspec:\n  clusterIP: None  # ClusterIP set to None for headless service.\n  ports:\n  - name: ddp  # Port for torchrun master<->worker node coms.\n    port: 29200\n    targetPort: 29200\n  selector:\n    torch-job: torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2\n    torch-node: '0'  # Selector for pods associated with this service.\n", "manifest_from": null, "merge_strategy": null, "set_owner_reference": null, "success_condition": null}, "retry_strategy": null, "scheduler_name": null, "script": null, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": null}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "torch-ddp-delete-torch-service", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": {"action": "delete", "failure_condition": null, "flags": ["service", "--selector", "torch-job=torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "-n", "argo"], "manifest": null, "manifest_from": null, "merge_strategy": null, "set_owner_reference": null, "success_condition": null}, "retry_strategy": null, "scheduler_name": null, "script": null, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": {"fail_fast": null, "target": null, "tasks": [{"arguments": {"artifacts": null, "parameters": null}, "continue_on": null, "dependencies": null, "depends": null, "hooks": null, "inline": null, "name": "torch-ddp-create-torch-service", "on_exit": null, "template": "torch-ddp-create-torch-service", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0", "on_exit": null, "template": "torch-ddp-0", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-1", "on_exit": null, "template": "torch-ddp-1", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-2", "on_exit": null, "template": "torch-ddp-2", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-3", "on_exit": null, "template": "torch-ddp-3", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-4", "on_exit": null, "template": "torch-ddp-4", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": "{{workflow.parameters.n_iter}}", "value_from": null}, {"default": null, "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": "{{workflow.parameters.n_seconds_sleep}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-create-torch-service", "hooks": null, "inline": null, "name": "torch-ddp-0-worker-5", "on_exit": null, "template": "torch-ddp-5", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": null}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-0", "hooks": null, "inline": null, "name": "torch-ddp-delete-torch-service", "on_exit": null, "template": "torch-ddp-delete-torch-service", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}, {"arguments": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "a", "value": "{{tasks.torch-ddp-0.outputs.parameters.duration}}", "value_from": null}]}, "continue_on": null, "dependencies": null, "depends": "torch-ddp-0", "hooks": null, "inline": null, "name": "show-duration-param-0", "on_exit": null, "template": "show-duration-param", "template_ref": null, "when": null, "with_items": null, "with_param": null, "with_sequence": null}]}, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": null}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "bettmensch-ai-dag", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": null, "scheduler_name": null, "script": null, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "0"}}, "metrics": null, "name": "torch-ddp-0", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "0", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": [{"container_port": 29200, "host_ip": null, "host_port": null, "name": "ddp", "protocol": "TCP"}], "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "1"}}, "metrics": null, "name": "torch-ddp-1", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "2"}}, "metrics": null, "name": "torch-ddp-2", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "2", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "3"}}, "metrics": null, "name": "torch-ddp-3", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "3", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "4"}}, "metrics": null, "name": "torch-ddp-4", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "4", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": "100", "description": null, "enum": null, "global_name": null, "name": "n_iter", "value": null, "value_from": null}, {"default": "10", "description": null, "enum": null, "global_name": null, "name": "n_seconds_sleep", "value": null, "value_from": null}, {"default": "null", "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": {"torch-job": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2", "torch-node": "5"}}, "metrics": null, "name": "torch-ddp-5", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "duration", "value": null, "value_from": {"config_map_key_ref": null, "default": null, "event": null, "expression": null, "jq_filter": null, "json_path": null, "parameter": null, "path": "duration", "supplied": null}}], "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": "topologySpreadConstraints:\n- maxSkew: 1\n  topologyKey: kubernetes.io/hostname\n  whenUnsatisfiable: DoNotSchedule\n  labelSelector:\n    matchExpressions:\n      - { key: torch-node, operator: In, values: ['0','1','2','3','4','5']}", "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": [{"name": "NCCL_DEBUG", "value": "INFO", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_min_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_nodes", "value": "6", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_node_rank", "value": "5", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_nproc_per_node", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_max_restarts", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_start_method", "value": "fork", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_backend", "value": "static", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_url", "value": "torch-ddp-0-cf224844-8416-4e44-84d7-539997d748d2.argo.svc.cluster.local", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_rdzv_endpoint_port", "value": "29200", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_run_id", "value": "1", "value_from": null}, {"name": "bettmensch_ai_distributed_torch_tee", "value": "0", "value_from": null}], "env_from": null, "image": "bettmensch88/bettmensch.ai-torch:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "300Mi"}, "requests": {"cpu": "100m", "memory": "300Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: n_iter = json.loads(r'''{{inputs.parameters.n_iter}}''')\nexcept: n_iter = r'''{{inputs.parameters.n_iter}}'''\ntry: n_seconds_sleep = json.loads(r'''{{inputs.parameters.n_seconds_sleep}}''')\nexcept: n_seconds_sleep = r'''{{inputs.parameters.n_seconds_sleep}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100, n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -> None:\n    \"\"\"When decorated with the torch_component decorator, implements a\n    bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes in\n    your K8s cluster.\"\"\"\n    import time\n    from datetime import datetime as dt\n    import torch\n    import torch.distributed as dist\n    has_gpu = torch.cuda.is_available()\n    print(f'GPU present: {has_gpu}')\n    if has_gpu:\n        dist.init_process_group(backend='nccl')\n    else:\n        dist.init_process_group(backend='gloo')\n    for i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a = torch.tensor([dist.get_rank()])\n        print(f'{i}/{n_iter}: @{dt.now()}')\n        print(f'{i}/{n_iter}: Backend {dist.get_backend()}')\n        print(f'{i}/{n_iter}: World size {dist.get_world_size()}')\n        print(f'{i}/{n_iter}: Rank {dist.get_rank()}')\n        print(f'{i}/{n_iter}: This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()} globally!')\n        if has_gpu:\n            device = torch.device('cuda:0')\n            device_count = torch.cuda.device_count()\n            print(f'{i}/{n_iter}: GPU count: {device_count}')\n            device_name = torch.cuda.get_device_name(0)\n            print(f'{i}/{n_iter}: GPU name: {device_name}')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f'{i}/{n_iter}: GPU property: {device_property}')\n        else:\n            device = torch.device('cpu')\n        a_placed = a.to(device)\n        print(f'{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}')\n        dist.all_reduce(a_placed)\n        print(f'{i}/{n_iter}: Post-`all_reduce` tensor: {a_placed}')\n        print('===================================================')\n    if duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom bettmensch_ai.components import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}, {"active_deadline_seconds": null, "affinity": null, "archive_location": null, "automount_service_account_token": null, "container": null, "container_set": null, "daemon": null, "dag": null, "data": null, "executor": null, "fail_fast": null, "host_aliases": null, "http": null, "init_containers": null, "inputs": {"artifacts": null, "parameters": [{"default": null, "description": null, "enum": null, "global_name": null, "name": "a", "value": null, "value_from": null}]}, "memoize": null, "metadata": {"annotations": null, "labels": null}, "metrics": null, "name": "show-duration-param", "node_selector": null, "outputs": {"artifacts": null, "exit_code": null, "parameters": null, "result": null}, "parallelism": null, "plugin": null, "pod_spec_patch": null, "priority": null, "priority_class_name": null, "resource": null, "retry_strategy": {"affinity": null, "backoff": null, "expression": null, "limit": "1", "retry_policy": "OnError"}, "scheduler_name": null, "script": {"args": null, "command": ["python"], "env": null, "env_from": null, "image": "bettmensch88/bettmensch.ai:3.11-latest", "image_pull_policy": "Always", "lifecycle": null, "liveness_probe": null, "name": "", "ports": null, "readiness_probe": null, "resources": {"limits": {"cpu": "100m", "memory": "100Mi"}, "requests": {"cpu": "100m", "memory": "100Mi"}}, "security_context": null, "source": "import os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport json\ntry: a = json.loads(r'''{{inputs.parameters.a}}''')\nexcept: a = r'''{{inputs.parameters.a}}'''\n\nfrom bettmensch_ai.io import InputParameter\n\ndef show_parameter(a: InputParameter) -> None:\n    \"\"\"When decorated with the bettmensch_ai.components.component decorator,\n    implements a bettmensch_ai.Component that prints the values of its\n    InputParameter.\"\"\"\n    print(f'Content of input parameter a is: {a}')\nshow_parameter(a)", "startup_probe": null, "stdin": null, "stdin_once": null, "termination_message_path": null, "termination_message_policy": null, "tty": null, "volume_devices": null, "volume_mounts": null, "working_dir": null}, "security_context": null, "service_account_name": null, "sidecars": null, "steps": null, "suspend": null, "synchronization": null, "timeout": null, "tolerations": null, "volumes": null}], "tolerations": null, "ttl_strategy": null, "volume_claim_gc": null, "volume_claim_templates": null, "volumes": null, "workflow_metadata": null, "workflow_template_ref": {"cluster_scope": null, "name": "pipeline-test-torch-cpu-pipeline-2n6rx"}}, "synchronization": null, "task_results_completion_status": {"pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1117923175": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1352423924": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-1396147642": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3153917983": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3155590524": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3218331537": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-3570269112": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-4186039992": true, "pipeline-test-torch-cpu-pipeline-2n6rx-flow-vgwzd-921081341": true}}}