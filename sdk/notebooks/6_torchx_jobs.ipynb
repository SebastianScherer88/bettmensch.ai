{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchx.specs as specs\n",
    "from torchx.components.utils import echo\n",
    "from torchx.components.dist import ddp\n",
    "from torchx.runner import get_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kubernetes://torchx/default:echo-sqqvtvbllgf7qc'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_runner().run(echo(msg=\"hello world\"), scheduler=\"kubernetes\", cfg={'queue':'default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resource(cpu=4, gpu=2, memMB=16000, capabilities={'node.kubernetes.io/instance-type': '<cloud instance type>'}, devices={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchx import specs\n",
    "specs.Resource(\n",
    "     cpu=4,\n",
    "     memMB=16000,\n",
    "     gpu=2,\n",
    "     capabilities={\n",
    "         \"node.kubernetes.io/instance-type\": \"<cloud instance type>\",\n",
    "     },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local_docker://torchx/dist_app-bc7d657r66sprc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_runner().run(ddp(script=\"./dist_app.py\",j=\"2x2\",cpu=1,memMB=100), scheduler=\"local_docker\", cfg={'queue':'default'}) # this wont display logs in the notebook chunk output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2024-06-11 11:46:50 INFO     Tracker configurations: {}\n",
      "torchx 2024-06-11 11:46:50 INFO     Checking for changes in workspace `file:///home/ubuntu/repositories/bettmensch.ai/sdk/notebooks`...\n",
      "torchx 2024-06-11 11:46:50 INFO     To disable workspaces pass: --workspace=\"\" from CLI or workspace=None programmatically.\n",
      "torchx 2024-06-11 11:46:50 INFO     Workspace `file:///home/ubuntu/repositories/bettmensch.ai/sdk/notebooks` resolved to filesystem path `/home/ubuntu/repositories/bettmensch.ai/sdk/notebooks`\n",
      "torchx 2024-06-11 11:46:51 INFO     Building workspace docker image (this may take a while)...\n",
      "torchx 2024-06-11 11:46:51 INFO     Built new image `sha256:ca1d4d20dbdb182006e235136f7c6d9fb5f2ecfc149916a56a75e5ea4f609ad8` based on original image `ghcr.io/pytorch/torchx:0.6.0` and changes in workspace `file:///home/ubuntu/repositories/bettmensch.ai/sdk/notebooks` for role[0]=dist_app.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_docker://torchx/dist_app-fdd10zq6td7fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2024-06-11 11:46:52 INFO     Waiting for the app to finish...\n",
      "dist_app/0 master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
      "dist_app/0 WARNING:torch.distributed.run:\n",
      "dist_app/0 *****************************************\n",
      "dist_app/0 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "dist_app/0 *****************************************\n",
      "dist_app/1 master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
      "dist_app/1 WARNING:torch.distributed.run:\n",
      "dist_app/1 *****************************************\n",
      "dist_app/1 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "dist_app/1 *****************************************\n",
      "dist_app/1 [0]:I am worker 2 of 4!\n",
      "dist_app/1 [1]:I am worker 3 of 4!\n",
      "dist_app/1 [1]:all_reduce output = tensor([6])\n",
      "dist_app/1 [0]:all_reduce output = tensor([6])\n",
      "dist_app/0 [0]:I am worker 0 of 4!\n",
      "dist_app/0 [1]:I am worker 1 of 4!\n",
      "dist_app/0 [1]:all_reduce output = tensor([6])\n",
      "dist_app/0 [0]:all_reduce output = tensor([6])\n",
      "torchx 2024-06-11 11:47:07 INFO     Job finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['torchx', 'run', '--scheduler', 'local_docker', 'dist.ddp', '-j', '2x2', '--script', './dist_app.py'], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\"torchx\", \"run\", \"--scheduler\", \"local_docker\", \"dist.ddp\", \"-j\", \"2x2\", \"--script\", \"./dist_app.py\"]) # CLI command equivalent to previous chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2024-06-11 14:38:21 INFO     Tracker configurations: {}\n",
      "torchx 2024-06-11 14:38:21 INFO     Checking for changes in workspace `file:///home/ubuntu/repositories/bettmensch.ai/sdk/notebooks`...\n",
      "torchx 2024-06-11 14:38:21 INFO     To disable workspaces pass: --workspace=\"\" from CLI or workspace=None programmatically.\n",
      "torchx 2024-06-11 14:38:21 INFO     Workspace `file:///home/ubuntu/repositories/bettmensch.ai/sdk/notebooks` resolved to filesystem path `/home/ubuntu/repositories/bettmensch.ai/sdk/notebooks`\n",
      "torchx 2024-06-11 14:38:21 INFO     Building workspace docker image (this may take a while)...\n",
      "torchx 2024-06-11 14:38:21 INFO     Built new image `sha256:71efb04c6efcbba90635eeb300e3e47d840957be106e851b16744b6daf3aea8b` based on original image `ghcr.io/pytorch/torchx:0.6.0` and changes in workspace `file:///home/ubuntu/repositories/bettmensch.ai/sdk/notebooks` for role[0]=dist_app.\n",
      "torchx 2024-06-11 14:38:21 INFO     pushing image bettmensch88/bettmensch.ai:71efb04c6efcbba90635eeb300e3e47d840957be106e851b16744b6daf3aea8b...\n",
      "\u001b[34mdocker push \u001b[0mThe push refers to repository [docker.io/bettmensch88/bettmensch.ai]\n",
      "\u001b[34mdocker push \u001b[0md7f0fea12366: Preparing \n",
      "\u001b[34mdocker push \u001b[0m00f8edd72a4a: Preparing \n",
      "\u001b[34mdocker push \u001b[0mea0918484cd4: Preparing \n",
      "\u001b[34mdocker push \u001b[0m83d5aeddd111: Preparing \n",
      "\u001b[34mdocker push \u001b[0m1171f4623f34: Preparing \n",
      "\u001b[34mdocker push \u001b[0mc5b358772923: Preparing \n",
      "\u001b[34mdocker push \u001b[0meb16036d83a1: Preparing \n",
      "\u001b[34mdocker push \u001b[0m527d732c9258: Preparing \n",
      "\u001b[34mdocker push \u001b[0m5f70bf18a086: Preparing \n",
      "\u001b[34mdocker push \u001b[0md62d6af2f4ef: Preparing \n",
      "\u001b[34mdocker push \u001b[0m2ead6e8c217d: Preparing \n",
      "\u001b[34mdocker push \u001b[0m6f37ca73c74f: Preparing \n",
      "\u001b[7F\u001b[2K\u001b[34mdocker push \u001b[0mc5b358772923: Waiting \u001b[7E\u001b[6F\u001b[2K\u001b[34mdocker push \u001b[0meb16036d83a1: Waiting \u001b[6E\u001b[5F\u001b[2K\u001b[34mdocker push \u001b[0m527d732c9258: Waiting \u001b[5E\u001b[4F\u001b[2K\u001b[34mdocker push \u001b[0m5f70bf18a086: Waiting \u001b[4E\u001b[3F\u001b[2K\u001b[34mdocker push \u001b[0md62d6af2f4ef: Waiting \u001b[3E\u001b[2F\u001b[2K\u001b[34mdocker push \u001b[0m2ead6e8c217d: Waiting \u001b[2E\u001b[1F\u001b[2K\u001b[34mdocker push \u001b[0m6f37ca73c74f: Waiting \u001b[1E\u001b[8F\u001b[2K\u001b[34mdocker push \u001b[0m1171f4623f34: Layer already exists \u001b[8E\u001b[9F\u001b[2K\u001b[34mdocker push \u001b[0m83d5aeddd111: Layer already exists \u001b[9E\u001b[12F\u001b[2K\u001b[34mdocker push \u001b[0md7f0fea12366: Layer already exists \u001b[12E\u001b[11F\u001b[2K\u001b[34mdocker push \u001b[0m00f8edd72a4a: Layer already exists \u001b[11E\u001b[10F\u001b[2K\u001b[34mdocker push \u001b[0mea0918484cd4: Layer already exists \u001b[10E\u001b[6F\u001b[2K\u001b[34mdocker push \u001b[0meb16036d83a1: Layer already exists \u001b[6E\u001b[4F\u001b[2K\u001b[34mdocker push \u001b[0m5f70bf18a086: Layer already exists \u001b[4E\u001b[5F\u001b[2K\u001b[34mdocker push \u001b[0m527d732c9258: Layer already exists \u001b[5E\u001b[3F\u001b[2K\u001b[34mdocker push \u001b[0md62d6af2f4ef: Layer already exists \u001b[3E\u001b[7F\u001b[2K\u001b[34mdocker push \u001b[0mc5b358772923: Layer already exists \u001b[7E\u001b[2F\u001b[2K\u001b[34mdocker push \u001b[0m2ead6e8c217d: Layer already exists \u001b[2E\u001b[1F\u001b[2K\u001b[34mdocker push \u001b[0m6f37ca73c74f: Layer already exists \u001b[1E\u001b[34mdocker push \u001b[0m71efb04c6efcbba90635eeb300e3e47d840957be106e851b16744b6daf3aea8b: digest: sha256:e042e528cbfccd0e5361663224bcb651f7599f8963228957d77c19603ef2bc59 size: 2833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubernetes://torchx/default:distapp-b6fz291zrkb1g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchx 2024-06-11 14:38:22 INFO     Launched app: kubernetes://torchx/default:distapp-b6fz291zrkb1g\n",
      "torchx 2024-06-11 14:38:22 INFO     AppStatus:\n",
      "    State: PENDING\n",
      "    Num Restarts: -1\n",
      "    Roles: \n",
      "    Msg: <NONE>\n",
      "    Structured Error Msg: <NONE>\n",
      "    UI URL: None\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['torchx', 'run', '--scheduler', 'kubernetes', '-cfg', 'queue=default,image_repo=bettmensch88/bettmensch.ai', 'dist.ddp', '--cpu', '1', '--memMB', '500', '-j', '2x2', '--script', './dist_app.py'], returncode=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"torchx\", \"run\", \"--scheduler\", \"kubernetes\", \"-cfg\",\"queue=default,image_repo=bettmensch88/bettmensch.ai\", \"dist.ddp\", \"--cpu\",\"1\",\"--memMB\",\"500\",\"-j\", \"2x2\", \"--script\", \"./dist_app.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
