apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubectl.kubernetes.io/default-container: main
    workflows.argoproj.io/node-id: pipeline-test-torch-pipeline-dggrw-flow-5c7p7-1478311883
    workflows.argoproj.io/node-name: pipeline-test-torch-pipeline-dggrw-flow-5c7p7.torch-ddp-0-worker-1
  creationTimestamp: "2024-07-09T21:29:37Z"
  labels:
    torch-node: "1"
    workflows.argoproj.io/completed: "true"
    workflows.argoproj.io/workflow: pipeline-test-torch-pipeline-dggrw-flow-5c7p7
  name: pipeline-test-torch-pipeline-dggrw-flow-5c7p7-torch-ddp-1-1478311883
  namespace: argo
  ownerReferences:
  - apiVersion: argoproj.io/v1alpha1
    blockOwnerDeletion: true
    controller: true
    kind: Workflow
    name: pipeline-test-torch-pipeline-dggrw-flow-5c7p7
    uid: 1330ac86-dc74-493f-bd25-9c03eacdec50
  resourceVersion: "115870"
  uid: 7d169eb0-d09b-4270-a333-d982beabee13
spec:
  containers:
  - command:
    - argoexec
    - wait
    - --loglevel
    - info
    - --log-format
    - text
    env:
    - name: ARGO_POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: ARGO_POD_UID
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.uid
    - name: GODEBUG
      value: x509ignoreCN=0
    - name: ARGO_WORKFLOW_NAME
      value: pipeline-test-torch-pipeline-dggrw-flow-5c7p7
    - name: ARGO_WORKFLOW_UID
      value: 1330ac86-dc74-493f-bd25-9c03eacdec50
    - name: ARGO_CONTAINER_NAME
      value: wait
    - name: ARGO_TEMPLATE
      value: '{"name":"torch-ddp-1","inputs":{"parameters":[{"name":"n_iter","default":"100","value":"12"},{"name":"n_seconds_sleep","default":"10","value":"5"},{"name":"duration","default":"null","value":"null"}]},"outputs":{"parameters":[{"name":"duration","valueFrom":{"path":"duration"}}]},"metadata":{"labels":{"torch-node":"1"}},"script":{"name":"","image":"bettmensch88/bettmensch.ai:3.11-latest","command":["python"],"ports":[{"name":"ddp","containerPort":29200,"protocol":"TCP"}],"env":[{"name":"bettmensch_ai_distributed_torch_min_nodes","value":"2"},{"name":"bettmensch_ai_distributed_torch_max_nodes","value":"2"},{"name":"bettmensch_ai_distributed_torch_node_rank","value":"1"},{"name":"bettmensch_ai_distributed_torch_nproc_per_node","value":"1"},{"name":"bettmensch_ai_distributed_torch_rdvz_endpoint_url","value":"torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local"},{"name":"bettmensch_ai_distributed_torch_rdvz_endpoint_port","value":"29200"},{"name":"bettmensch_ai_distributed_torch_run_id","value":"1"},{"name":"bettmensch_ai_distributed_torch_tee","value":"3"}],"resources":{},"imagePullPolicy":"Always","source":"import
        os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport
        json\ntry: n_iter = json.loads(r''''''12'''''')\nexcept: n_iter = r''''''12''''''\ntry:
        n_seconds_sleep = json.loads(r''''''5'''''')\nexcept: n_seconds_sleep = r''''''5''''''\n\nfrom
        bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration
        = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100,
        n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -\u003e
        None:\n    \"\"\"When decorated with the torch_component decorator, implements
        a bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes
        in your K8s cluster.\"\"\"\n    has_gpu = torch.cuda.is_available()\n    print(f''GPU
        present: {has_gpu}'')\n    if has_gpu:\n        dist.init_process_group(backend=''nccl'')\n    else:\n        dist.init_process_group(backend=''gloo'')\n    for
        i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a
        = torch.tensor([dist.get_rank()])\n        print(f''{i}/{n_iter}: @{dt.now()}'')\n        print(f''{i}/{n_iter}:
        Backend {dist.get_backend()}'')\n        print(f''{i}/{n_iter}: World size
        {dist.get_world_size()}'')\n        print(f''{i}/{n_iter}: Rank {dist.get_rank()}'')\n        print(f''{i}/{n_iter}:
        This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()}
        globally!'')\n        if has_gpu:\n            device = torch.device(''cuda:0'')\n            device_count
        = torch.cuda.device_count()\n            print(f''{i}/{n_iter}: GPU count:
        {device_count}'')\n            device_name = torch.cuda.get_device_name(0)\n            print(f''{i}/{n_iter}:
        GPU name: {device_name}'')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f''{i}/{n_iter}:
        GPU property: {device_property}'')\n        else:\n            device = torch.device(''cpu'')\n        a_placed
        = a.to(device)\n        print(f''{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}'')\n        dist.all_reduce(a_placed)\n        print(f''{i}/{n_iter}:
        Post-`all_reduce` tensor: {a_placed}'')\n        print(''==================================================='')\n    if
        duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom
        bettmensch_ai import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)"}}'
    - name: ARGO_NODE_ID
      value: pipeline-test-torch-pipeline-dggrw-flow-5c7p7-1478311883
    - name: ARGO_INCLUDE_SCRIPT_OUTPUT
      value: "false"
    - name: ARGO_DEADLINE
      value: "0001-01-01T00:00:00Z"
    - name: ARGO_PROGRESS_FILE
      value: /var/run/argo/progress
    - name: ARGO_PROGRESS_PATCH_TICK_DURATION
      value: 1m0s
    - name: ARGO_PROGRESS_FILE_TICK_DURATION
      value: 3s
    - name: AWS_STS_REGIONAL_ENDPOINTS
      value: regional
    - name: AWS_DEFAULT_REGION
      value: us-east-2
    - name: AWS_REGION
      value: us-east-2
    - name: AWS_ROLE_ARN
      value: arn:aws:iam::743582000746:role/bettmensch-ai-pipelines-artifact-role
    - name: AWS_WEB_IDENTITY_TOKEN_FILE
      value: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
    image: quay.io/argoproj/argoexec:v3.5.6
    imagePullPolicy: IfNotPresent
    name: wait
    resources:
      requests:
        cpu: 10m
        memory: 64Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /mainctrfs/argo/staging
      name: argo-staging
    - mountPath: /tmp
      name: tmp-dir-argo
      subPath: "0"
    - mountPath: /var/run/argo
      name: var-run-argo
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-nvw8v
      readOnly: true
    - mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount
      name: aws-iam-token
      readOnly: true
  - args:
    - /argo/staging/script
    command:
    - /var/run/argo/argoexec
    - emissary
    - --loglevel
    - info
    - --log-format
    - text
    - --
    - python
    env:
    - name: bettmensch_ai_distributed_torch_min_nodes
      value: "2"
    - name: bettmensch_ai_distributed_torch_max_nodes
      value: "2"
    - name: bettmensch_ai_distributed_torch_node_rank
      value: "1"
    - name: bettmensch_ai_distributed_torch_nproc_per_node
      value: "1"
    - name: bettmensch_ai_distributed_torch_rdvz_endpoint_url
      value: torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local
    - name: bettmensch_ai_distributed_torch_rdvz_endpoint_port
      value: "29200"
    - name: bettmensch_ai_distributed_torch_run_id
      value: "1"
    - name: bettmensch_ai_distributed_torch_tee
      value: "3"
    - name: ARGO_CONTAINER_NAME
      value: main
    - name: ARGO_TEMPLATE
      value: '{"name":"torch-ddp-1","inputs":{"parameters":[{"name":"n_iter","default":"100","value":"12"},{"name":"n_seconds_sleep","default":"10","value":"5"},{"name":"duration","default":"null","value":"null"}]},"outputs":{"parameters":[{"name":"duration","valueFrom":{"path":"duration"}}]},"metadata":{"labels":{"torch-node":"1"}},"script":{"name":"","image":"bettmensch88/bettmensch.ai:3.11-latest","command":["python"],"ports":[{"name":"ddp","containerPort":29200,"protocol":"TCP"}],"env":[{"name":"bettmensch_ai_distributed_torch_min_nodes","value":"2"},{"name":"bettmensch_ai_distributed_torch_max_nodes","value":"2"},{"name":"bettmensch_ai_distributed_torch_node_rank","value":"1"},{"name":"bettmensch_ai_distributed_torch_nproc_per_node","value":"1"},{"name":"bettmensch_ai_distributed_torch_rdvz_endpoint_url","value":"torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local"},{"name":"bettmensch_ai_distributed_torch_rdvz_endpoint_port","value":"29200"},{"name":"bettmensch_ai_distributed_torch_run_id","value":"1"},{"name":"bettmensch_ai_distributed_torch_tee","value":"3"}],"resources":{},"imagePullPolicy":"Always","source":"import
        os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport
        json\ntry: n_iter = json.loads(r''''''12'''''')\nexcept: n_iter = r''''''12''''''\ntry:
        n_seconds_sleep = json.loads(r''''''5'''''')\nexcept: n_seconds_sleep = r''''''5''''''\n\nfrom
        bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration
        = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100,
        n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -\u003e
        None:\n    \"\"\"When decorated with the torch_component decorator, implements
        a bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes
        in your K8s cluster.\"\"\"\n    has_gpu = torch.cuda.is_available()\n    print(f''GPU
        present: {has_gpu}'')\n    if has_gpu:\n        dist.init_process_group(backend=''nccl'')\n    else:\n        dist.init_process_group(backend=''gloo'')\n    for
        i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a
        = torch.tensor([dist.get_rank()])\n        print(f''{i}/{n_iter}: @{dt.now()}'')\n        print(f''{i}/{n_iter}:
        Backend {dist.get_backend()}'')\n        print(f''{i}/{n_iter}: World size
        {dist.get_world_size()}'')\n        print(f''{i}/{n_iter}: Rank {dist.get_rank()}'')\n        print(f''{i}/{n_iter}:
        This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()}
        globally!'')\n        if has_gpu:\n            device = torch.device(''cuda:0'')\n            device_count
        = torch.cuda.device_count()\n            print(f''{i}/{n_iter}: GPU count:
        {device_count}'')\n            device_name = torch.cuda.get_device_name(0)\n            print(f''{i}/{n_iter}:
        GPU name: {device_name}'')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f''{i}/{n_iter}:
        GPU property: {device_property}'')\n        else:\n            device = torch.device(''cpu'')\n        a_placed
        = a.to(device)\n        print(f''{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}'')\n        dist.all_reduce(a_placed)\n        print(f''{i}/{n_iter}:
        Post-`all_reduce` tensor: {a_placed}'')\n        print(''==================================================='')\n    if
        duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom
        bettmensch_ai import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)"}}'
    - name: ARGO_NODE_ID
      value: pipeline-test-torch-pipeline-dggrw-flow-5c7p7-1478311883
    - name: ARGO_INCLUDE_SCRIPT_OUTPUT
      value: "false"
    - name: ARGO_DEADLINE
      value: "0001-01-01T00:00:00Z"
    - name: ARGO_PROGRESS_FILE
      value: /var/run/argo/progress
    - name: ARGO_PROGRESS_PATCH_TICK_DURATION
      value: 1m0s
    - name: ARGO_PROGRESS_FILE_TICK_DURATION
      value: 3s
    - name: AWS_STS_REGIONAL_ENDPOINTS
      value: regional
    - name: AWS_DEFAULT_REGION
      value: us-east-2
    - name: AWS_REGION
      value: us-east-2
    - name: AWS_ROLE_ARN
      value: arn:aws:iam::743582000746:role/bettmensch-ai-pipelines-artifact-role
    - name: AWS_WEB_IDENTITY_TOKEN_FILE
      value: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
    image: bettmensch88/bettmensch.ai:3.11-latest
    imagePullPolicy: Always
    name: main
    ports:
    - containerPort: 29200
      name: ddp
      protocol: TCP
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /argo/staging
      name: argo-staging
    - mountPath: /var/run/argo
      name: var-run-argo
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-nvw8v
      readOnly: true
    - mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount
      name: aws-iam-token
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  initContainers:
  - command:
    - argoexec
    - init
    - --loglevel
    - info
    - --log-format
    - text
    env:
    - name: ARGO_POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: ARGO_POD_UID
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.uid
    - name: GODEBUG
      value: x509ignoreCN=0
    - name: ARGO_WORKFLOW_NAME
      value: pipeline-test-torch-pipeline-dggrw-flow-5c7p7
    - name: ARGO_WORKFLOW_UID
      value: 1330ac86-dc74-493f-bd25-9c03eacdec50
    - name: ARGO_CONTAINER_NAME
      value: init
    - name: ARGO_TEMPLATE
      value: '{"name":"torch-ddp-1","inputs":{"parameters":[{"name":"n_iter","default":"100","value":"12"},{"name":"n_seconds_sleep","default":"10","value":"5"},{"name":"duration","default":"null","value":"null"}]},"outputs":{"parameters":[{"name":"duration","valueFrom":{"path":"duration"}}]},"metadata":{"labels":{"torch-node":"1"}},"script":{"name":"","image":"bettmensch88/bettmensch.ai:3.11-latest","command":["python"],"ports":[{"name":"ddp","containerPort":29200,"protocol":"TCP"}],"env":[{"name":"bettmensch_ai_distributed_torch_min_nodes","value":"2"},{"name":"bettmensch_ai_distributed_torch_max_nodes","value":"2"},{"name":"bettmensch_ai_distributed_torch_node_rank","value":"1"},{"name":"bettmensch_ai_distributed_torch_nproc_per_node","value":"1"},{"name":"bettmensch_ai_distributed_torch_rdvz_endpoint_url","value":"torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local"},{"name":"bettmensch_ai_distributed_torch_rdvz_endpoint_port","value":"29200"},{"name":"bettmensch_ai_distributed_torch_run_id","value":"1"},{"name":"bettmensch_ai_distributed_torch_tee","value":"3"}],"resources":{},"imagePullPolicy":"Always","source":"import
        os\nimport sys\nsys.path.append(os.getcwd())\n\n# --- preprocessing\nimport
        json\ntry: n_iter = json.loads(r''''''12'''''')\nexcept: n_iter = r''''''12''''''\ntry:
        n_seconds_sleep = json.loads(r''''''5'''''')\nexcept: n_seconds_sleep = r''''''5''''''\n\nfrom
        bettmensch_ai.io import InputParameter\n\nfrom bettmensch_ai.io import OutputParameter\nduration
        = OutputParameter(\"duration\")\n\ndef torch_ddp(n_iter: InputParameter=100,
        n_seconds_sleep: InputParameter=10, duration: OutputParameter=None) -\u003e
        None:\n    \"\"\"When decorated with the torch_component decorator, implements
        a bettmensch_ai.TorchComponent that runs a torch DDP across pods and nodes
        in your K8s cluster.\"\"\"\n    has_gpu = torch.cuda.is_available()\n    print(f''GPU
        present: {has_gpu}'')\n    if has_gpu:\n        dist.init_process_group(backend=''nccl'')\n    else:\n        dist.init_process_group(backend=''gloo'')\n    for
        i in range(1, n_iter + 1):\n        time.sleep(n_seconds_sleep)\n        a
        = torch.tensor([dist.get_rank()])\n        print(f''{i}/{n_iter}: @{dt.now()}'')\n        print(f''{i}/{n_iter}:
        Backend {dist.get_backend()}'')\n        print(f''{i}/{n_iter}: World size
        {dist.get_world_size()}'')\n        print(f''{i}/{n_iter}: Rank {dist.get_rank()}'')\n        print(f''{i}/{n_iter}:
        This makes me worker process {dist.get_rank() + 1}/{dist.get_world_size()}
        globally!'')\n        if has_gpu:\n            device = torch.device(''cuda:0'')\n            device_count
        = torch.cuda.device_count()\n            print(f''{i}/{n_iter}: GPU count:
        {device_count}'')\n            device_name = torch.cuda.get_device_name(0)\n            print(f''{i}/{n_iter}:
        GPU name: {device_name}'')\n            device_property = torch.cuda.get_device_capability(device)\n            print(f''{i}/{n_iter}:
        GPU property: {device_property}'')\n        else:\n            device = torch.device(''cpu'')\n        a_placed
        = a.to(device)\n        print(f''{i}/{n_iter}: Pre-`all_reduce` tensor: {a_placed}'')\n        dist.all_reduce(a_placed)\n        print(f''{i}/{n_iter}:
        Post-`all_reduce` tensor: {a_placed}'')\n        print(''==================================================='')\n    if
        duration is not None:\n        duration_seconds = n_iter * n_seconds_sleep\n        duration.assign(duration_seconds)\n\nfrom
        bettmensch_ai import torch_distribute\n\ntorch_distribute_decorator=torch_distribute()\ntorch_distributed_function=torch_distribute_decorator(torch_ddp)\n\ntorch_distributed_function(n_iter,n_seconds_sleep,duration)"}}'
    - name: ARGO_NODE_ID
      value: pipeline-test-torch-pipeline-dggrw-flow-5c7p7-1478311883
    - name: ARGO_INCLUDE_SCRIPT_OUTPUT
      value: "false"
    - name: ARGO_DEADLINE
      value: "0001-01-01T00:00:00Z"
    - name: ARGO_PROGRESS_FILE
      value: /var/run/argo/progress
    - name: ARGO_PROGRESS_PATCH_TICK_DURATION
      value: 1m0s
    - name: ARGO_PROGRESS_FILE_TICK_DURATION
      value: 3s
    - name: AWS_STS_REGIONAL_ENDPOINTS
      value: regional
    - name: AWS_DEFAULT_REGION
      value: us-east-2
    - name: AWS_REGION
      value: us-east-2
    - name: AWS_ROLE_ARN
      value: arn:aws:iam::743582000746:role/bettmensch-ai-pipelines-artifact-role
    - name: AWS_WEB_IDENTITY_TOKEN_FILE
      value: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
    image: quay.io/argoproj/argoexec:v3.5.6
    imagePullPolicy: IfNotPresent
    name: init
    resources:
      requests:
        cpu: 10m
        memory: 64Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /argo/staging
      name: argo-staging
    - mountPath: /var/run/argo
      name: var-run-argo
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-nvw8v
      readOnly: true
    - mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount
      name: aws-iam-token
      readOnly: true
  nodeName: ip-10-0-49-230.us-east-2.compute.internal
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: aws-iam-token
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          audience: sts.amazonaws.com
          expirationSeconds: 86400
          path: token
  - emptyDir: {}
    name: var-run-argo
  - emptyDir: {}
    name: tmp-dir-argo
  - emptyDir: {}
    name: argo-staging
  - name: kube-api-access-nvw8v
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-07-09T21:31:52Z"
    status: "False"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2024-07-09T21:29:40Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-07-09T21:31:49Z"
    reason: PodFailed
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-07-09T21:31:49Z"
    reason: PodFailed
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-07-09T21:29:37Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://2d02d051f592b90b7a4e2b911bc79da46ccf8f6037b506ced8882dcb7e793b5b
    image: docker.io/bettmensch88/bettmensch.ai:3.11-latest
    imageID: docker.io/bettmensch88/bettmensch.ai@sha256:6f91555359a45c9084445722edae7caf88d804475cdfc6a80080de5694cd4d66
    lastState: {}
    name: main
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://2d02d051f592b90b7a4e2b911bc79da46ccf8f6037b506ced8882dcb7e793b5b
        exitCode: 1
        finishedAt: "2024-07-09T21:31:49Z"
        reason: Error
        startedAt: "2024-07-09T21:29:41Z"
  - containerID: containerd://1e3af679683f93b23f28995965fab1010eeb619b52f27d890fd73a219036afbd
    image: quay.io/argoproj/argoexec:v3.5.6
    imageID: quay.io/argoproj/argoexec@sha256:c7405360797347aee20cf252c2c0cbed045077e58bf572042e118acefc74e94e
    lastState: {}
    name: wait
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://1e3af679683f93b23f28995965fab1010eeb619b52f27d890fd73a219036afbd
        exitCode: 1
        finishedAt: "2024-07-09T21:31:49Z"
        message: 'open /var/run/argo/outputs/parameters/duration: no such file or
          directory'
        reason: Error
        startedAt: "2024-07-09T21:29:40Z"
  hostIP: 10.0.49.230
  hostIPs:
  - ip: 10.0.49.230
  initContainerStatuses:
  - containerID: containerd://da0091d50a6c24f9d1db40c76909426d32cdb407fc0aec4e0aecd8183feb0c51
    image: quay.io/argoproj/argoexec:v3.5.6
    imageID: quay.io/argoproj/argoexec@sha256:c7405360797347aee20cf252c2c0cbed045077e58bf572042e118acefc74e94e
    lastState: {}
    name: init
    ready: true
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://da0091d50a6c24f9d1db40c76909426d32cdb407fc0aec4e0aecd8183feb0c51
        exitCode: 0
        finishedAt: "2024-07-09T21:29:39Z"
        reason: Completed
        startedAt: "2024-07-09T21:29:38Z"
  phase: Failed
  podIP: 10.0.49.12
  podIPs:
  - ip: 10.0.49.12
  qosClass: Burstable
  startTime: "2024-07-09T21:29:37Z"
