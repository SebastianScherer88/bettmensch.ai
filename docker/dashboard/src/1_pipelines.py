import streamlit as st

st.set_page_config(
    page_title="Pipelines",
    page_icon=":twisted_rightwards_arrows:",
    layout="wide",
)
from typing import Dict, List, Tuple  # noqa: E402

import pandas as pd  # noqa: E402
from bettmensch_ai.pipelines import hera_client  # noqa: E402
from bettmensch_ai.server import (  # noqa: E402
    DagVisualizationItems,
    DagVisualizationSettings,
)
from bettmensch_ai.server import RegisteredPipeline as Pipeline  # noqa: E402
from hera.workflows.models import (  # noqa: E402
    WorkflowTemplate as WorkflowTemplateModel,
)
from streamlit_flow import streamlit_flow  # noqa: E402
from streamlit_flow.interfaces import (  # noqa: E402
    StreamlitFlowEdge,
    StreamlitFlowNode,
)
from utils import PIPELINE_NODE_EMOJI_MAP, add_logo, get_colors  # noqa: E402


def get_workflow_templates() -> List[WorkflowTemplateModel]:

    workflow_template_models = hera_client.list_workflow_templates().items

    if workflow_template_models:
        return workflow_template_models
    else:
        return []


def get_pipeline_meta_data(
    registered_pipelines: List[WorkflowTemplateModel],
) -> List[Dict]:
    """Retrieves the metadata field from all the ArgoWorkflowTemplate CRs
    obtained by `get_workflow_templates`.

    Args:
        registered_pipelines (List[
            IoArgoprojWorkflowV1alpha1WorkflowTemplate]):
            The ArgoWorkflowTemplate CRs obtained by `get_workflow_templates`

    Returns:
        List[Dict]: A list of dictionaries containing the metadata of each
            ArgoWorkflowTemplate resource.
    """

    return [
        registered_pipeline.metadata.to_dict()
        for registered_pipeline in registered_pipelines
    ]


def display_pipeline_summary_table(
    pipeline_meta_data: List[Dict],
) -> pd.DataFrame:
    """Generates a summary table displaying the key specs of the registered
    pipelines.

    Args:
        pipeline_meta_data (List[Dict]): The pipeline metadata generated by
            `get_pipeline_meta_data`.

    Returns:
        pd.DataFrame: The pipeline summary table shown on the frontend.
    """

    st.markdown("## Registered pipelines")

    pipeline_summary_df = (
        pd.DataFrame(pipeline_meta_data)[["name", "uid", "creation_timestamp"]]
        .rename(
            columns={
                "name": "Name",
                "uid": "ID",
                "creation_timestamp": "Created",
            }
        )
        .sort_values(by="Created", ignore_index=True)
    )

    st.dataframe(pipeline_summary_df, hide_index=True)


def get_pipeline_names(pipeline_meta_data: List[Dict]) -> List[str]:
    """Generates a list of names of all registered pipelines.

    Args:
        pipeline_meta_data (List[Dict]): The pipeline metadata generated by
            `get_pipeline_meta_data`.

    Returns:
        List[str]: The names of all available registered pipelines.
    """

    return [resource_meta["name"] for resource_meta in pipeline_meta_data]


def get_formatted_pipeline_data(
    registered_pipelines: List[WorkflowTemplateModel],
    pipeline_names: List[str],  # noqa: E501
) -> Dict:
    """Generates structured pipeline data for easier frontend useage.

    Args:
        registered_pipelines (List[
            hera.workflows.models.WorkflowTemplate]): The WorkflowTemplate
                models obtained by `get_workflow_templates`
        pipeline_names (List[str]): The names of pipelines generated by
            `get_pipeline_names`.

    Returns:
        Dict: The formatted pipeline data.
    """

    formatted_pipeline_data = {
        "object": {},
        "metadata": {},
        "inputs": {},
        "dag": {},
        "templates": {},
    }

    for i, (resource_name, registered_pipeline) in enumerate(
        zip(pipeline_names, registered_pipelines)
    ):
        try:
            pipeline_dict = Pipeline.from_hera_workflow_template_model(
                registered_pipeline
            ).model_dump()
            formatted_pipeline_data["object"][
                resource_name
            ] = Pipeline.from_hera_workflow_template_model(registered_pipeline)
            formatted_pipeline_data["metadata"][resource_name] = pipeline_dict[
                "metadata"
            ]
            formatted_pipeline_data["inputs"][resource_name] = pipeline_dict[
                "inputs"
            ]
            formatted_pipeline_data["dag"][resource_name] = pipeline_dict[
                "dag"
            ]  # noqa: E501
            formatted_pipeline_data["templates"][
                resource_name
            ] = pipeline_dict[  # noqa: E501
                "templates"
            ]
        except Exception as e:
            st.write(
                f"Oops! Could not collect data for Pipeline {resource_name}: "
                f"{e} Please make sure the workflow template was created with "
                "the bettmensch.ai SDK and was submitted successfully."
            )

    return formatted_pipeline_data


def display_pipeline_dropdown(pipeline_names: List[str]) -> str:
    """Display the pipeline selection dropdown.

    Args:
        pipeline_names (List[str]): The names of pipelines generated by
            `get_pipeline_names`.

    Returns:
        str: The name of the user selected pipeline.
    """

    # display pipeline selection dropdown
    selected_pipeline = st.selectbox(
        "Select a Pipeline:", options=pipeline_names, index=0
    )

    return selected_pipeline


def display_pipeline_dag(
    formatted_pipeline_data: Dict,
    selected_pipeline: str,
    display_pipeline_ios: bool,
    dag_image_height: int,
) -> Tuple[DagVisualizationItems, Dict]:
    """_summary_

    Args:
        formatted_pipeline_data (_type_): The formatted pipeline data generated
            by `get_formatted_pipeline_data`.
        selected_pipeline (str): The name of the user selected pipeline.
        display_pipeline_ios (bool): The toggle value of the user selected
            pipeline dag I/O detail level in the flow chart.
        dag_image_height (int): The height of the react flow plugin plot.

    Returns:
        Tuple[DagVisualizationItems,Dict]: The specification for the streamlit
            ReactFlow visualization plugin, and the return of that plugin.
    """

    selected_pipeline_instance = formatted_pipeline_data["object"][
        selected_pipeline
    ]

    dag_visualization_items = (
        selected_pipeline_instance.create_dag_visualization_schema(
            display_pipeline_ios,
        )
    )

    dag_visualization_element = streamlit_flow(
        nodes=[
            StreamlitFlowNode(**node.model_dump())
            for node in dag_visualization_items.nodes
        ],
        edges=[
            StreamlitFlowEdge(**connection.model_dump())
            for connection in dag_visualization_items.connections
        ],
        **DagVisualizationSettings(
            style={
                "backgroundColor": get_colors(
                    "custom"
                ).secondaryBackgroundColor  # noqa: E501
            },
            height=dag_image_height,
        ).model_dump(),
    )

    return dag_visualization_items, dag_visualization_element


def display_pipeline_dag_selection(
    formatted_pipeline_data: Dict,
    selected_pipeline: str,
    dag_visualization_element,
    tab_container_height: int,
):
    """Generates a tabbed, in depth view of the user selected DAG task node
    element.

    Args:
        formatted_pipeline_data (Dict): The formatted pipeline data as
            generated by `get_formatted_pipeline_data`
        selected_pipeline (str): The user selected pipeline name.
        dag_visualization_element (_type_): The user selected element from the
            DAG visuals, as returned by `display_pipeline_dag`
    """

    try:
        element_type = dag_visualization_element["elementType"]
        element_id = dag_visualization_element["id"]
        element_is_task_node = (element_type == "node") and (
            len(element_id.split("_")) == 1
        )

        if element_is_task_node:
            st.markdown(
                f"### {PIPELINE_NODE_EMOJI_MAP['task']} Component: `{element_id}`"  # noqa: E501
            )
            task_inputs_tab, task_outputs_tab, task_script_tab = st.tabs(
                ["Component Inputs", "Component Outputs", "Component Script"]
            )
            pipeline = formatted_pipeline_data["object"][selected_pipeline]
            task = pipeline.get_dag_task(element_id).model_dump()

            with task_inputs_tab:
                with st.container(height=tab_container_height, border=False):
                    # build task input parameters table
                    if task["inputs"]["parameters"]:
                        task_inputs_parameters_df = pd.DataFrame(
                            task["inputs"]["parameters"]
                        )
                        task_inputs_parameters_formatted_df = pd.concat(
                            [
                                task_inputs_parameters_df.drop(
                                    ["source", "value_from"], axis=1
                                ),
                                task_inputs_parameters_df["source"].apply(
                                    pd.Series
                                ),
                            ],
                            axis=1,
                        ).rename(
                            columns={
                                "name": "Name",
                                "value": "Default",
                                "node": "Upstream Task",
                                "output_name": "Upstream Output",
                                "output_type": "Upstream Type",
                            },
                            inplace=False,
                        )
                    else:
                        task_inputs_parameters_formatted_df = pd.DataFrame()

                    # build task input artifact table
                    if task["inputs"]["artifacts"]:
                        task_inputs_artifacts_df = pd.DataFrame(
                            task["inputs"]["artifacts"]
                        )
                        task_inputs_artifacts_formatted_df = pd.concat(
                            [
                                task_inputs_artifacts_df.drop(
                                    ["source"], axis=1
                                ),
                                task_inputs_artifacts_df["source"].apply(
                                    pd.Series
                                ),
                            ],
                            axis=1,
                        ).rename(
                            columns={
                                "name": "Name",
                                "node": "Upstream Task",
                                "output_name": "Upstream Output",
                                "output_type": "Upstream Type",
                            },
                            inplace=False,
                        )
                    else:
                        task_inputs_artifacts_formatted_df = pd.DataFrame()

                    st.write(":page_with_curl: Parameters")
                    st.dataframe(
                        task_inputs_parameters_formatted_df, hide_index=True
                    )
                    st.write(":open_file_folder: Artifacts")
                    st.dataframe(
                        task_inputs_artifacts_formatted_df, hide_index=True
                    )

            with task_outputs_tab:
                with st.container(height=tab_container_height, border=False):
                    # build task output parameters table
                    if task["outputs"]["parameters"]:
                        task_outputs_parameters_df = pd.DataFrame(
                            task["outputs"]["parameters"]
                        )
                        task_outputs_parameters_formatted_df = (
                            task_outputs_parameters_df.drop(
                                "value_from", axis=1
                            ).rename(
                                columns={
                                    "name": "Name",
                                },
                                inplace=False,
                            )
                        )
                    else:
                        task_outputs_parameters_formatted_df = pd.DataFrame()

                    # build task output artifact table
                    if task["outputs"]["artifacts"]:
                        task_outputs_artifacts_df = pd.DataFrame(
                            task["outputs"]["artifacts"]
                        )
                        task_outputs_artifacts_formatted_df = (
                            task_outputs_artifacts_df.drop(
                                "path", axis=1
                            ).rename(
                                columns={
                                    "name": "Name",
                                },
                                inplace=False,
                            )
                        )
                    else:
                        task_outputs_artifacts_formatted_df = pd.DataFrame()

                    st.write(":page_with_curl: Parameters")
                    st.dataframe(
                        task_outputs_parameters_formatted_df, hide_index=True
                    )
                    st.write(":open_file_folder: Artifacts")
                    st.dataframe(
                        task_outputs_artifacts_formatted_df, hide_index=True
                    )

            with task_script_tab:
                with st.container(height=tab_container_height, border=False):
                    st.json(
                        pipeline.get_template(task["template"]).model_dump()[
                            "script"
                        ]
                    )
        else:
            st.markdown(
                f"### {PIPELINE_NODE_EMOJI_MAP['task']} Component: None"
            )
            st.write(
                "Select a component by clicking on the corresponding "
                f"{PIPELINE_NODE_EMOJI_MAP['task']} node."
            )

    except TypeError:
        st.markdown(f"### {PIPELINE_NODE_EMOJI_MAP['task']} Component: None")
        st.write(
            "Select a `Component` by clicking on the corresponding "
            f"{PIPELINE_NODE_EMOJI_MAP['task']} node."
        )


def display_selected_pipeline(
    formatted_pipeline_data: Dict,
    selected_pipeline: str,
    tab_container_height: int = 420,
    dag_image_height: int = 1100,
):
    """Utility to display DAG flow chart and all relevant specs in tabbed
    layout for a user selected pipeline.

    Args:
        formatted_pipeline_data (Dict): The formatted pipeline data as obtained
            by `get_formatted_pipeline_data`.
        selected_pipeline (str): The name of the user selected pipeline.
    """

    dag_col, spec_col = st.columns([3, 2])

    with dag_col:
        display_pipeline_ios = st.toggle("Display pipeline & component I/O")
        (
            dag_visualization_schema,
            dag_visualization_element,
        ) = display_pipeline_dag(
            formatted_pipeline_data,
            selected_pipeline,
            display_pipeline_ios,
            dag_image_height,
        )

    # display pipeline level data
    with spec_col:
        st.markdown(
            "### :twisted_rightwards_arrows: Pipeline: `"
            f"{selected_pipeline}`"
        )

        tab_inputs, tab_metadata, tab_dag, tab_templates = st.tabs(
            [
                "Pipeline Inputs",
                "Pipeline Meta Data",
                "Pipeline DAG",
                "Pipeline Templates",
            ]
        )

        with tab_inputs:
            with st.container(height=tab_container_height, border=False):
                pipeline_inputs = formatted_pipeline_data["inputs"][
                    selected_pipeline
                ]
                pipeline_inputs_formatted_df = pd.DataFrame(
                    pipeline_inputs
                ).rename(
                    columns={
                        "name": "Name",
                        "value": "Default",
                    }
                )
                st.write(":page_with_curl: Parameters")
                st.dataframe(pipeline_inputs_formatted_df, hide_index=True)

        with tab_metadata:
            with st.container(height=tab_container_height, border=False):
                st.markdown("### Spec")
                st.json(
                    formatted_pipeline_data["metadata"][selected_pipeline],
                    expanded=True,
                )

        with tab_dag:
            with st.container(height=tab_container_height, border=False):
                st.markdown("### Spec")
                st.json(
                    formatted_pipeline_data["dag"][selected_pipeline],
                    expanded=True,
                )

        with tab_templates:
            with st.container(height=tab_container_height, border=False):
                st.markdown("### Spec")
                st.json(
                    formatted_pipeline_data["templates"][selected_pipeline],
                    expanded=True,
                )

        # display task level data
        display_pipeline_dag_selection(
            formatted_pipeline_data,
            selected_pipeline,
            dag_visualization_element,
            tab_container_height,
        )

    return dag_visualization_schema, dag_visualization_element


def main():
    """Utility function to render the pipeline resources."""

    st.markdown(
        """
        # :twisted_rightwards_arrows: Pipelines

        A `Pipeline` is the *definition* of a workflow, i.e. it describes a DAG
        declaring the logic and dependencies that will be executd at runtime.
        """
    )

    workflow_templates = get_workflow_templates()

    meta_data = get_pipeline_meta_data(workflow_templates)
    display_pipeline_summary_table(meta_data)

    names = get_pipeline_names(meta_data)

    formatted_pipeline_data = get_formatted_pipeline_data(
        workflow_templates, names
    )

    selected_pipeline = display_pipeline_dropdown(names)

    (
        dag_visualization_schema,
        dag_visualization_element,
    ) = display_selected_pipeline(formatted_pipeline_data, selected_pipeline)

    with st.sidebar:
        add_logo(sidebar=True)


main()
