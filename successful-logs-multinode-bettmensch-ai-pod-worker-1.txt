Torch distributed launch config settings: {'min_nodes': 2, 'max_nodes': 2, 'node_rank': 1, 'nproc_per_node': 1, 'rdzv_backend': 'static', 'rdvz_endpoint_url': 'multinode-bettmensch-ai-pod-driver-svc.default.svc.cluster.local', 'rdvz_endpoint_port': 29500, 'run_id': '1', 'role': '', 'max_restarts': 3, 'monitor_interval': 30.0, 'redirects': '3', 'tee': '3', 'log_dir': None, 'log_line_prefix_template': None}
/usr/local/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:1606: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  pg._register_backend(torch.device(device), backend_type, backend_class)
GPU present: False
1/10: @2024-07-09 21:24:38.845950
1/10: Backend gloo
1/10: World size 2
1/10: Rank 1
1/10: This makes me worker process 2/2 globally!
1/10: Pre-`all_reduce` tensor: tensor([1])
1/10: Post-`all_reduce` tensor: tensor([1])
===================================================
2/10: @2024-07-09 21:24:41.876351
2/10: Backend gloo
2/10: World size 2
2/10: Rank 1
2/10: This makes me worker process 2/2 globally!
2/10: Pre-`all_reduce` tensor: tensor([1])
2/10: Post-`all_reduce` tensor: tensor([1])
===================================================
3/10: @2024-07-09 21:24:44.877956
3/10: Backend gloo
3/10: World size 2
3/10: Rank 1
3/10: This makes me worker process 2/2 globally!
3/10: Pre-`all_reduce` tensor: tensor([1])
3/10: Post-`all_reduce` tensor: tensor([1])
===================================================
4/10: @2024-07-09 21:24:47.879595
4/10: Backend gloo
4/10: World size 2
4/10: Rank 1
4/10: This makes me worker process 2/2 globally!
4/10: Pre-`all_reduce` tensor: tensor([1])
4/10: Post-`all_reduce` tensor: tensor([1])
===================================================
5/10: @2024-07-09 21:24:50.881158
5/10: Backend gloo
5/10: World size 2
5/10: Rank 1
5/10: This makes me worker process 2/2 globally!
5/10: Pre-`all_reduce` tensor: tensor([1])
5/10: Post-`all_reduce` tensor: tensor([1])
===================================================
6/10: @2024-07-09 21:24:53.882663
6/10: Backend gloo
6/10: World size 2
6/10: Rank 1
6/10: This makes me worker process 2/2 globally!
6/10: Pre-`all_reduce` tensor: tensor([1])
6/10: Post-`all_reduce` tensor: tensor([1])
===================================================
7/10: @2024-07-09 21:24:56.884454
7/10: Backend gloo
7/10: World size 2
7/10: Rank 1
7/10: This makes me worker process 2/2 globally!
7/10: Pre-`all_reduce` tensor: tensor([1])
7/10: Post-`all_reduce` tensor: tensor([1])
===================================================
8/10: @2024-07-09 21:24:59.886535
8/10: Backend gloo
8/10: World size 2
8/10: Rank 1
8/10: This makes me worker process 2/2 globally!
8/10: Pre-`all_reduce` tensor: tensor([1])
8/10: Post-`all_reduce` tensor: tensor([1])
===================================================
9/10: @2024-07-09 21:25:02.888103
9/10: Backend gloo
9/10: World size 2
9/10: Rank 1
9/10: This makes me worker process 2/2 globally!
9/10: Pre-`all_reduce` tensor: tensor([1])
9/10: Post-`all_reduce` tensor: tensor([1])
===================================================
10/10: @2024-07-09 21:25:05.889668
10/10: Backend gloo
10/10: World size 2
10/10: Rank 1
10/10: This makes me worker process 2/2 globally!
10/10: Pre-`all_reduce` tensor: tensor([1])
10/10: Post-`all_reduce` tensor: tensor([1])
===================================================
