Torch distributed launch config settings: {'min_nodes': 2, 'max_nodes': 2, 'node_rank': 0, 'nproc_per_node': 1, 'rdzv_backend': 'static', 'rdvz_endpoint_url': 'torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local', 'rdvz_endpoint_port': 29200, 'run_id': '1', 'role': '', 'max_restarts': 3, 'monitor_interval': 30.0, 'redirects': '3', 'tee': '3', 'log_dir': None, 'log_line_prefix_template': None}
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 131, in _main
    prepare(preparation_data)
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 246, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 297, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen runpy>", line 291, in run_path
  File "<frozen runpy>", line 98, in _run_module_code
  File "<frozen runpy>", line 88, in _run_code
  File "/argo/staging/script", line 57, in <module>
    torch_distributed_function(n_iter,n_seconds_sleep,duration)
  File "/src/bettmensch-ai/sdk/bettmensch_ai/torch_utils.py", line 120, in wrapper
    elastic_launch(
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 254, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 733, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 705, in _initialize_workers
    self._rendezvous(worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 548, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
Torch distributed launch config settings: {'min_nodes': 2, 'max_nodes': 2, 'node_rank': 0, 'nproc_per_node': 1, 'rdzv_backend': 'static', 'rdvz_endpoint_url': 'torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local', 'rdvz_endpoint_port': 29200, 'run_id': '1', 'role': '', 'max_restarts': 3, 'monitor_interval': 30.0, 'redirects': '3', 'tee': '3', 'log_dir': None, 'log_line_prefix_template': None}
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] failed (exitcode: 1) local_rank: 0 (pid: 16) of fn: torch_ddp (start_method: spawn)
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] Traceback (most recent call last):
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 656, in _poll
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     self._pc.join(-1)
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 177, in join
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     raise ProcessExitedException(
E0709 21:30:16.481000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 1
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 131, in _main
    prepare(preparation_data)
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 246, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 297, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen runpy>", line 291, in run_path
  File "<frozen runpy>", line 98, in _run_module_code
  File "<frozen runpy>", line 88, in _run_code
  File "/argo/staging/script", line 57, in <module>
    torch_distributed_function(n_iter,n_seconds_sleep,duration)
  File "/src/bettmensch-ai/sdk/bettmensch_ai/torch_utils.py", line 120, in wrapper
    elastic_launch(
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 254, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 733, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 705, in _initialize_workers
    self._rendezvous(worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 548, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
Torch distributed launch config settings: {'min_nodes': 2, 'max_nodes': 2, 'node_rank': 0, 'nproc_per_node': 1, 'rdzv_backend': 'static', 'rdvz_endpoint_url': 'torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local', 'rdvz_endpoint_port': 29200, 'run_id': '1', 'role': '', 'max_restarts': 3, 'monitor_interval': 30.0, 'redirects': '3', 'tee': '3', 'log_dir': None, 'log_line_prefix_template': None}
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] failed (exitcode: 1) local_rank: 0 (pid: 17) of fn: torch_ddp (start_method: spawn)
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] Traceback (most recent call last):
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 656, in _poll
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     self._pc.join(-1)
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 177, in join
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     raise ProcessExitedException(
E0709 21:30:46.492000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 1
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 131, in _main
    prepare(preparation_data)
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 246, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 297, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen runpy>", line 291, in run_path
  File "<frozen runpy>", line 98, in _run_module_code
  File "<frozen runpy>", line 88, in _run_code
  File "/argo/staging/script", line 57, in <module>
    torch_distributed_function(n_iter,n_seconds_sleep,duration)
  File "/src/bettmensch-ai/sdk/bettmensch_ai/torch_utils.py", line 120, in wrapper
    elastic_launch(
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 254, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 733, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 705, in _initialize_workers
    self._rendezvous(worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 548, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
Torch distributed launch config settings: {'min_nodes': 2, 'max_nodes': 2, 'node_rank': 0, 'nproc_per_node': 1, 'rdzv_backend': 'static', 'rdvz_endpoint_url': 'torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local', 'rdvz_endpoint_port': 29200, 'run_id': '1', 'role': '', 'max_restarts': 3, 'monitor_interval': 30.0, 'redirects': '3', 'tee': '3', 'log_dir': None, 'log_line_prefix_template': None}
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] failed (exitcode: 1) local_rank: 0 (pid: 18) of fn: torch_ddp (start_method: spawn)
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] Traceback (most recent call last):
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 656, in _poll
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     self._pc.join(-1)
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 177, in join
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     raise ProcessExitedException(
E0709 21:31:16.499000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 1
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 131, in _main
    prepare(preparation_data)
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 246, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/usr/local/lib/python3.11/multiprocessing/spawn.py", line 297, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen runpy>", line 291, in run_path
  File "<frozen runpy>", line 98, in _run_module_code
  File "<frozen runpy>", line 88, in _run_code
  File "/argo/staging/script", line 57, in <module>
    torch_distributed_function(n_iter,n_seconds_sleep,duration)
  File "/src/bettmensch-ai/sdk/bettmensch_ai/torch_utils.py", line 120, in wrapper
    elastic_launch(
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 254, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 733, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 705, in _initialize_workers
    self._rendezvous(worker_group)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py", line 548, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29200 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29200 (errno: 98 - Address already in use).
Torch distributed launch config settings: {'min_nodes': 2, 'max_nodes': 2, 'node_rank': 0, 'nproc_per_node': 1, 'rdzv_backend': 'static', 'rdvz_endpoint_url': 'torch-ddp-0-e7f79f1f-09db-42fa-bfbb-a465847e2851.argo.svc.cluster.local', 'rdvz_endpoint_port': 29200, 'run_id': '1', 'role': '', 'max_restarts': 3, 'monitor_interval': 30.0, 'redirects': '3', 'tee': '3', 'log_dir': None, 'log_line_prefix_template': None}
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] failed (exitcode: 1) local_rank: 0 (pid: 19) of fn: torch_ddp (start_method: spawn)
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] Traceback (most recent call last):
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 656, in _poll
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     self._pc.join(-1)
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]   File "/usr/local/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 177, in join
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695]     raise ProcessExitedException(
E0709 21:31:46.509000 139861632367488 torch/distributed/elastic/multiprocessing/api.py:695] torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 1
Traceback (most recent call last):
  File "/argo/staging/script", line 57, in <module>
    torch_distributed_function(n_iter,n_seconds_sleep,duration)
  File "/src/bettmensch-ai/sdk/bettmensch_ai/torch_utils.py", line 120, in wrapper
    elastic_launch(
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
torch_ddp FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-09_21:31:46
  host      : pipeline-test-torch-pipeline-dggrw-flow-5c7p7-torch-ddp-0-42358
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 19)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
time="2024-07-09T21:31:49.156Z" level=info msg="sub-process exited" argo=true error="<nil>"
time="2024-07-09T21:31:49.174Z" level=error msg="cannot save parameter duration" argo=true error="open duration: no such file or directory"
Error: exit status 1
