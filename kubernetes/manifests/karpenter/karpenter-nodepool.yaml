apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: on-demand-cpu
spec:
  template:
    spec:
      nodeClassRef:
        name: bettmensch-ai-default
      requirements:
        - key: "karpenter.k8s.aws/instance-category"
          operator: In
          values: ["c", "m", "r", "t"]
        - key: "karpenter.k8s.aws/instance-cpu"
          operator: In
          values: ["4", "8", "16", "32"]
        - key: "kubernetes.io/arch"
          operator: In
          values: ["amd64"]
        - key: "karpenter.k8s.aws/instance-generation"
          operator: Gt
          values: ["2"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
  limits:
    cpu: 100
    memory: 1000Gi
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 15m # ~5 minutes required for larger images, otherwise karpenter will deprovision before pods are running
    expireAfter: 2h
---
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: short-run-gpu
spec:
  template:
    spec:
      nodeClassRef:
        name: bettmensch-ai-default
      requirements:
        - key: "karpenter.k8s.aws/instance-category"
          operator: In
          values: ["p","g"]
        - key: "karpenter.k8s.aws/instance-generation"
          operator: Gt
          values: ["2"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot","on-demand"]
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: "NoSchedule"
  limits:
    cpu: 100
    memory: 1000Gi
    nvidia.com/gpu: 8
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 15m # dont go lower to prevent decomissioning bc of image pull phase
    expireAfter: 1h # limit GPU nodes to 3 ours - enough to train annotated transformer on one GPU (~2.8h)
---
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: long-run-gpu
spec:
  template:
    spec:
      nodeClassRef:
        name: bettmensch-ai-default
      requirements:
        - key: "karpenter.k8s.aws/instance-category"
          operator: In
          values: ["p","g"]
        - key: "karpenter.k8s.aws/instance-generation"
          operator: Gt
          values: ["2"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: "NoSchedule"
        - key: long-run-gpu
          value: "true"
          effect: NoSchedule
  limits:
    cpu: 200
    memory: 2000Gi
    nvidia.com/gpu: 8
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 30m # larger training images take longer to pull
    expireAfter: 24h # limit GPU nodes to 12h ours
